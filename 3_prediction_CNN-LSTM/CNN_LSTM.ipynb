{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ORQ15-2cDiYp",
    "outputId": "fb186242-56a5-4c5c-ba83-c6daf0c8050a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import LSTM, Dense,  Conv2D, MaxPooling2D, TimeDistributed, Flatten, InputLayer, Reshape, Conv1D, MaxPooling1D, Bidirectional, Dropout, ReLU\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.optimizers import Adadelta, SGD, Adagrad\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import r2_score\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "\n",
    "#%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJTx0mMoX2EH"
   },
   "source": [
    "# LOADING DATASETS\n",
    "Converting J to KWh and all the date/time strings to timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2JQxhSVmEFfX",
    "outputId": "d2ca970b-f77e-4b16-e866-4240ddbd5999"
   },
   "outputs": [],
   "source": [
    "#df_2017 = pd.read_csv('/content/drive/MyDrive/eplusout_2017_with_year.csv')[:-1]\n",
    "df_2017 = pd.read_csv('../data/output_eplus/eplusout_2017_with_year.csv')[:-1]\n",
    "df_2017['DistrictHeating:Facility [J](TimeStep)'] = df_2017['DistrictHeating:Facility [J](TimeStep)']/3.6e6\n",
    "df_2017['DistrictCooling:Facility [J](TimeStep)'] = df_2017['DistrictCooling:Facility [J](TimeStep)']/3.6e6\n",
    "df_2017['InteriorLights:Electricity [J](TimeStep)'] = df_2017['InteriorLights:Electricity [J](TimeStep)']/3.6e6\n",
    "df_2017['Temp_IN'] = df_2017[['BLOCK1:CORRIDOR:Zone Operative Temperature [C](TimeStep)',\n",
    "                              'BLOCK1:ZONE2:Zone Operative Temperature [C](TimeStep)',\n",
    "                              'BLOCK1:ZONE1:Zone Operative Temperature [C](TimeStep)']].mean(1)\n",
    "df_2017['Heating setpoint'] = 21\n",
    "df_2017['Heating setpoint'][6*24*134:6*24*257] = 0\n",
    "df_2017['Cooling setpoint'] = 24\n",
    "df_2017['Cooling setpoint'][:6*24*104] = 0\n",
    "df_2017['Cooling setpoint'][6*24*287:] = 0\n",
    "plt.figure()\n",
    "plt.title('2017')\n",
    "df_2017['DistrictHeating:Facility [J](TimeStep)'].plot()\n",
    "df_2017['DistrictCooling:Facility [J](TimeStep)'].plot()\n",
    "df_2017['InteriorLights:Electricity [J](TimeStep)'].plot()\n",
    "plt.show()\n",
    "\n",
    "#df_2018 = pd.read_csv('/content/drive/MyDrive/eplusout_2018_with_year.csv')[:-1]\n",
    "df_2018 = pd.read_csv('../data/output_eplus/eplusout_2018_with_year.csv')[:-1]\n",
    "df_2018['DistrictHeating:Facility [J](TimeStep)'] = df_2018['DistrictHeating:Facility [J](TimeStep)']/3.6e6\n",
    "df_2018['DistrictCooling:Facility [J](TimeStep)'] = df_2018['DistrictCooling:Facility [J](TimeStep)']/3.6e6\n",
    "df_2018['InteriorLights:Electricity [J](TimeStep)'] = df_2018['InteriorLights:Electricity [J](TimeStep)']/3.6e6\n",
    "df_2018['Temp_IN'] = df_2018[['BLOCK1:CORRIDOR:Zone Operative Temperature [C](TimeStep)',\n",
    "                              'BLOCK1:ZONE2:Zone Operative Temperature [C](TimeStep)',\n",
    "                              'BLOCK1:ZONE1:Zone Operative Temperature [C](TimeStep)']].mean(1)\n",
    "df_2018['Heating setpoint'] = 21\n",
    "df_2018['Heating setpoint'][6*24*134:6*24*257] = 0\n",
    "df_2018['Cooling setpoint'] = 24\n",
    "df_2018['Cooling setpoint'][:6*24*104] = 0\n",
    "df_2018['Cooling setpoint'][6*24*287:] = 0\n",
    "plt.figure()\n",
    "plt.title('2018')\n",
    "df_2018['DistrictHeating:Facility [J](TimeStep)'].plot()\n",
    "df_2018['DistrictCooling:Facility [J](TimeStep)'].plot()\n",
    "df_2018['InteriorLights:Electricity [J](TimeStep)'].plot()\n",
    "plt.show()\n",
    "\n",
    "#df_2019 = pd.read_csv('/content/drive/MyDrive/eplusout_2019_with_year.csv')[:-1]\n",
    "df_2019 = pd.read_csv('../data/output_eplus/eplusout_2019_with_year.csv')[:-1]\n",
    "df_2019['DistrictHeating:Facility [J](TimeStep)'] = df_2019['DistrictHeating:Facility [J](TimeStep)']/3.6e6\n",
    "df_2019['DistrictCooling:Facility [J](TimeStep)'] = df_2019['DistrictCooling:Facility [J](TimeStep)']/3.6e6\n",
    "df_2019['InteriorLights:Electricity [J](TimeStep)'] = df_2019['InteriorLights:Electricity [J](TimeStep)']/3.6e6\n",
    "df_2019['Temp_IN'] = df_2019[['BLOCK1:CORRIDOR:Zone Operative Temperature [C](TimeStep)',\n",
    "                              'BLOCK1:ZONE2:Zone Operative Temperature [C](TimeStep)',\n",
    "                              'BLOCK1:ZONE1:Zone Operative Temperature [C](TimeStep)']].mean(1)\n",
    "df_2019['Heating setpoint'] = 21\n",
    "df_2019['Heating setpoint'][6*24*134:6*24*257] = 0\n",
    "df_2019['Cooling setpoint'] = 24\n",
    "df_2019['Cooling setpoint'][:6*24*104] = 0\n",
    "df_2019['Cooling setpoint'][6*24*287:] = 0\n",
    "plt.figure()\n",
    "plt.title('2019')\n",
    "df_2019['DistrictHeating:Facility [J](TimeStep)'].plot()\n",
    "df_2019['DistrictCooling:Facility [J](TimeStep)'].plot()\n",
    "df_2019['InteriorLights:Electricity [J](TimeStep)'].plot()\n",
    "plt.show()\n",
    "\n",
    "ts = []\n",
    "for elem in df_2017['Date/Time']:\n",
    "    date, time = elem.split(' ')\n",
    "    if (time == '24:00:00'):\n",
    "        time = '00:00:00'\n",
    "    timestamp = datetime.strptime(f'{date} {time}', '%m/%d/%Y %H:%M:%S')\n",
    "    if (time == '00:00:00'):\n",
    "        timestamp += timedelta(days=1)\n",
    "    ts.append(timestamp)\n",
    "df_2017['Date/Time'] = pd.to_datetime(ts, format='%m/%d/%Y %H:%M:%S')\n",
    "\n",
    "ts = []\n",
    "for elem in df_2018['Date/Time']:\n",
    "    date, time = elem.split(' ')\n",
    "    if (time == '24:00:00'):\n",
    "        time = '00:00:00'\n",
    "    timestamp = datetime.strptime(f'{date} {time}', '%m/%d/%Y %H:%M:%S')\n",
    "    if (time == '00:00:00'):\n",
    "        timestamp += timedelta(days=1)\n",
    "    ts.append(timestamp)\n",
    "df_2018['Date/Time'] = pd.to_datetime(ts, format='%m/%d/%Y %H:%M:%S')\n",
    "\n",
    "ts = []\n",
    "for elem in df_2019['Date/Time']:\n",
    "    date, time = elem.split(' ')\n",
    "    if (time == '24:00:00'):\n",
    "        time = '00:00:00'\n",
    "    timestamp = datetime.strptime(f'{date} {time}', '%m/%d/%Y %H:%M:%S')\n",
    "    if (time == '00:00:00'):\n",
    "        timestamp += timedelta(days=1)\n",
    "    ts.append(timestamp)\n",
    "df_2019['Date/Time'] = pd.to_datetime(ts, format='%m/%d/%Y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyPwbPbAQcfi"
   },
   "source": [
    "## Join 2017 and 2018 in training set and assign test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "voJPoM2-QZ2U"
   },
   "outputs": [],
   "source": [
    "df_train = pd.concat([df_2017, df_2018], axis=0)\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_test = df_2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3tTTIC_r5XgX"
   },
   "source": [
    "# FEATURES AND REGRESSANDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Nl3OH925Xgd"
   },
   "outputs": [],
   "source": [
    "regressands = [\n",
    "            #   'DistrictHeating:Facility [J](TimeStep)',\n",
    "              'DistrictCooling:Facility [J](TimeStep)',\n",
    "            #   'InteriorLights:Electricity [J](TimeStep)',\n",
    "            #   'Temp_IN'\n",
    "              ]\n",
    "features = [\n",
    "            'Environment:Site Outdoor Air Drybulb Temperature [C](TimeStep)',\n",
    "            'Environment:Site Outdoor Air Dewpoint Temperature [C](TimeStep)',\n",
    "            'Environment:Site Outdoor Air Barometric Pressure [Pa](TimeStep)',\n",
    "            'Environment:Site Wind Speed [m/s](TimeStep)',\n",
    "            'Environment:Site Wind Direction [deg](TimeStep)',\n",
    "            'Environment:Site Diffuse Solar Radiation Rate per Area [W/m2](TimeStep)',\n",
    "            'Environment:Site Direct Solar Radiation Rate per Area [W/m2](TimeStep)',\n",
    "            'Environment:Site Solar Azimuth Angle [deg](TimeStep)',\n",
    "            'Environment:Site Solar Altitude Angle [deg](TimeStep)',\n",
    "            'Temp_IN',  # comment out if predicting Temp_IN\n",
    "            #'Heating setpoint',  # comment out unnecessary features depending on the regressand\n",
    "            'Cooling setpoint'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TkA6sdM1beyw"
   },
   "source": [
    "# SINGLE RUN OF THE MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Q95_igO1x8I"
   },
   "source": [
    "##  Train, val and test generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tEPVumZb2Uo"
   },
   "source": [
    "### Selecting Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "id": "l_0ZJ44TbfSg",
    "outputId": "0c82c19b-1cb2-41cc-cbdb-2fe233423f79"
   },
   "outputs": [],
   "source": [
    "days = []\n",
    "months = []\n",
    "years = []\n",
    "hours = []\n",
    "minutes = []\n",
    "for timestamp in df_train['Date/Time']:\n",
    "    days.append(timestamp.day)\n",
    "    months.append(timestamp.month)\n",
    "    years.append(timestamp.year)\n",
    "    hours.append(timestamp.hour)\n",
    "    minutes.append(timestamp.minute)\n",
    "\n",
    "X_train = pd.DataFrame()\n",
    "X_train['day'] = days\n",
    "X_train['month'] = months\n",
    "X_train['year'] = years\n",
    "X_train['hour'] = hours\n",
    "X_train['minute'] = minutes\n",
    "X_train.index = df_train.index\n",
    "\n",
    "X_train = X_train.join(df_train[np.concatenate((features, regressands))])\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5OcPY5yc1UA"
   },
   "source": [
    "### Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7w3sdtZkvOO7"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "normalized_X_train=(X_train-X_train.min())/(X_train.max()-X_train.min())\n",
    "normalized_X_train.dropna(axis=1, inplace=True)\n",
    "y_train_min, y_train_max = X_train[regressands].min(), X_train[regressands].max()\n",
    "y_train_mean, y_train_std = X_train[regressands].mean(), X_train[regressands].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S9egUrtKdB0T"
   },
   "source": [
    "### From multivariate time serie to supervised problem\n",
    "We prepare a train set which will associate a set of previous [window] realizations of the features+regressands with the [forseen] following regressands values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J2OUssWlHYF6"
   },
   "outputs": [],
   "source": [
    "window = 6  # number of past values used to predict the next ones, in this case one hour (6*10min)\n",
    "forseen = 6  # number of future sample to predict, in this case one hour (6*10min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LYqjIlNuc-HB"
   },
   "outputs": [],
   "source": [
    "trainX, trainY = [], []\n",
    "for j in range(window, len(normalized_X_train.index)-forseen, 1):\n",
    "    input, val = normalized_X_train.values[j-window:j, :], normalized_X_train.values[j:j+forseen,-len(regressands):]  # I know that regressand is in the last column\n",
    "    trainX.append(input)\n",
    "    trainY.append(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2-qsFVAerYP"
   },
   "source": [
    "### Separation of the validation set\n",
    "We took off some random samples from the train set to generate the val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GqMacacsPbgg",
    "outputId": "74174616-22f9-4532-8400-d4f6a8a3339d"
   },
   "outputs": [],
   "source": [
    "#val_size = round(len(trainX)*0.25)\n",
    "val_size = 6*24*60  # 2 months\n",
    "valX = []\n",
    "valY = []\n",
    "for v in range(val_size):\n",
    "    rand_i = random.choice(range(len(trainX)))\n",
    "    valX.append(trainX.pop(rand_i))\n",
    "    valY.append(trainY.pop(rand_i))\n",
    "\n",
    "trainX = np.array(trainX)\n",
    "trainY = np.array(trainY)\n",
    "valX = np.array(valX)\n",
    "valY = np.array(valY)\n",
    "print('trainX shape ', trainX.shape)\n",
    "print('trainY shape ', trainY.shape)\n",
    "print('valX shape ', valX.shape)\n",
    "print('valY shape ', valY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBjhfUnP5Xgh"
   },
   "source": [
    "### Preparing the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "83nYyGbKazNv"
   },
   "outputs": [],
   "source": [
    "days = []\n",
    "months = []\n",
    "years = []\n",
    "hours = []\n",
    "minutes = []\n",
    "for timestamp in df_test['Date/Time']:\n",
    "    days.append(timestamp.day)\n",
    "    months.append(timestamp.month)\n",
    "    years.append(timestamp.year)\n",
    "    hours.append(timestamp.hour)\n",
    "    minutes.append(timestamp.minute)\n",
    "\n",
    "X_test = pd.DataFrame()\n",
    "X_test['day'] = days\n",
    "X_test['month'] = months\n",
    "X_test['year'] = years\n",
    "X_test['hour'] = hours\n",
    "X_test['minute'] = minutes\n",
    "X_test.describe()\n",
    "X_test.index = df_test.index\n",
    "X_test = X_test.join(df_test[np.concatenate((features, regressands))])\n",
    "\n",
    "X_test = X_test.astype('float32')\n",
    "normalized_X_test=(X_test-X_train.min())/(X_train.max()-X_train.min())\n",
    "#normalized_X_test=(X_test-X_test.min())/(X_test.max()-X_test.min())\n",
    "\n",
    "normalized_X_test.dropna(axis=1, inplace=True)\n",
    "#y_test_min, y_test_max = X_test[regressands].min(), X_test[regressands].max()\n",
    "\n",
    "testX = []\n",
    "for t in range(window, len(normalized_X_test.index)-forseen, forseen):\n",
    "    testX.append(normalized_X_test.values[t-window:t, :])\n",
    "testX = np.array(testX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-_peblefQ8B"
   },
   "source": [
    "## Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nvA8Js6G5Xgf",
    "outputId": "14969efb-89d3-47e8-a79e-8fae1a853c78"
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "model_choice = 'cnn_lstm'  # 'single_lstm', 'stacked_lstm', 'lstm_cnn'\n",
    "\n",
    "if model_choice == 'single_lstm':\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(window, X_train.shape[1])))\n",
    "    model.add(LSTM(64)) \n",
    "    model.add(Dense(forseen*len(regressands)))\n",
    "    model.add(ReLU())\n",
    "    model.add(Reshape((forseen, len(regressands))))\n",
    "\n",
    "if model_choice == 'stacked_lstm':\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(window, X_train.shape[1])))\n",
    "    model.add(LSTM(64, return_sequences=True))  # in questo modo LSTM si aspetta di ricevere in input i 50 istanti precedenti, ciascuno con 3 valori\n",
    "    model.add(LSTM(32)) # add return_sequences=True, in the previous layer\n",
    "    model.add(Dense(forseen*len(regressands)))\n",
    "    model.add(ReLU())\n",
    "    model.add(Reshape((forseen, len(regressands))))\n",
    "\n",
    "if model_choice == 'cnn_lstm':\n",
    "    model = Sequential()\n",
    "    model.add(Reshape((window, normalized_X_train.shape[1], 1), input_shape=(window, normalized_X_train.shape[1])))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(2,1), strides=1, padding='valid', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,1), strides=(1,1)))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(2,1), strides=1, padding='valid', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,1), strides=(1,1)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(64, activation='tanh'))\n",
    "    model.add(Dense(32))\n",
    "    model.add(Dense(forseen*len(regressands)))\n",
    "    model.add(ReLU())\n",
    "    model.add(Reshape((forseen, len(regressands))))\n",
    "\n",
    "#lr_schedule = ExponentialDecay(initial_learning_rate=0.2, decay_steps=8000, decay_rate=0.9, staircase=False)  # 0.0053 17/30\n",
    "#opt = Adagrad(learning_rate=lr_schedule)\n",
    "model.compile(loss='mse', optimizer='adam', metrics='mean_absolute_error')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G_1uQVpppbEv"
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', patience=3)\n",
    "mc = ModelCheckpoint(f'{regressands[0].split(\":\")[0]}/{model_choice}.h5', monitor='val_loss', mode='min', save_weights_only=True, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zvGY_RHLihCt"
   },
   "source": [
    "## Training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "paTXCN5Oes2h",
    "outputId": "b385ac13-690a-4dac-8342-fde3f63cbcce"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    model.load_weights(f'{regressands[0].split(\":\")[0]}/{model_choice}.h5')\n",
    "    print('Already trained model found!')\n",
    "except:\n",
    "    history = model.fit(x=trainX, y=trainY, batch_size=10, epochs=30, shuffle=True, validation_data=(valX, valY), callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "DMufZFxtWOA6",
    "outputId": "f1b6eef3-1940-470b-ecfe-f9f90aaca121"
   },
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MloGA4jjo9j3"
   },
   "source": [
    "## Test phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 655
    },
    "id": "xEPFDNQc5Xgh",
    "outputId": "e2444577-c84c-4b97-f94a-60a33debbf5e"
   },
   "outputs": [],
   "source": [
    "model.load_weights(f'{regressands[0].split(\":\")[0]}/{model_choice}.h5')\n",
    "final_pred = {}\n",
    "\n",
    "out = model.predict(testX)\n",
    "\n",
    "for i, reg in enumerate(regressands):\n",
    "    temp = out[:, :, i] * (y_train_max[i] - y_train_min[i]) + y_train_min[i]\n",
    "    # temp = out[:, :, i] * y_train_std[i]\n",
    "    final_pred[reg] = temp.reshape((testX.shape[0]*forseen))\n",
    "    err = (abs(X_test.values[window:window+len(final_pred[reg]), -len(regressands)+i]-final_pred[reg])).mean()\n",
    "    rmse = math.sqrt(((X_test.values[window:window+len(final_pred[reg]), -len(regressands)+i]-final_pred[reg])**2).mean())\n",
    "    print(f'MAE ({regressands[0].split(\":\")[0]}): ', round(err, 4))\n",
    "    print(f'RMSE ({regressands[0].split(\":\")[0]}): ', round(rmse, 4))\n",
    "\n",
    "    fig = plt.figure(figsize=(18,10))\n",
    "    plt.title(reg)\n",
    "    plt.plot(X_test.values[window:window+len(final_pred[reg]), 5+len(features)+i], label='original')\n",
    "    plt.plot(final_pred[reg], label=f'prediction')\n",
    "    plt.ylabel(f'{regressands[0].split(\":\")[0]} [kWh]')\n",
    "    plt.xlabel('Time steps (10 minutes resolution)')\n",
    "    plt.title(f'{regressands[0].split(\":\")[0]} for the year 2019')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "id": "AyIR6yCYIeHJ",
    "outputId": "e5df7a52-4039-4931-dc91-103194c8b1a1"
   },
   "outputs": [],
   "source": [
    "# July 2019\n",
    "for i, reg in enumerate(regressands):\n",
    "    fig = plt.figure(figsize=(18,10))\n",
    "    plt.title(reg)\n",
    "    plt.plot(X_test.values[6*24*181:6*24*212, 5+len(features)+i], label='original')\n",
    "    plt.plot(final_pred[reg][6*24*181:6*24*212], label=f'prediction')\n",
    "    plt.ylabel(f'{regressands[0].split(\":\")[0]} [kWh]')\n",
    "    plt.xlabel('Time steps (10 minutes resolution)')\n",
    "    plt.title(f'{regressands[0].split(\":\")[0]} for July 2019')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lkjwi-qUERaY"
   },
   "source": [
    "# (EXTRA) FORECASTING WINDOW OPTIMIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "joyri2mpfPXy"
   },
   "outputs": [],
   "source": [
    "# Loading the dataset and splitting it into train and test subsets\n",
    "days = []\n",
    "months = []\n",
    "hours = []\n",
    "years = []\n",
    "minutes = []\n",
    "for timestamp in df_train['Date/Time']:\n",
    "    days.append(timestamp.day)\n",
    "    months.append(timestamp.month)\n",
    "    hours.append(timestamp.hour)\n",
    "    years.append(timestamp.year)\n",
    "    minutes.append(timestamp.minute)\n",
    "\n",
    "X_train = pd.DataFrame()\n",
    "X_train['day'] = days\n",
    "X_train['month'] = months\n",
    "X_train['year'] = years\n",
    "X_train['hour'] = hours\n",
    "X_train['minute'] = minutes\n",
    "\n",
    "X_train.index = df_train.index\n",
    "X_train = X_train.join(df_train[np.concatenate((features, regressands))])\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "normalized_X_train=(X_train-X_train.min())/(X_train.max()-X_train.min())\n",
    "y_train_min, y_train_max = X_train[regressands].min(), X_train[regressands].max()\n",
    "\n",
    "\n",
    "# Loading the test dataset\n",
    "days = []\n",
    "months = []\n",
    "years = []\n",
    "hours = []\n",
    "minutes = []\n",
    "for timestamp in df_test['Date/Time']:\n",
    "    days.append(timestamp.day)\n",
    "    months.append(timestamp.month)\n",
    "    years.append(timestamp.year)\n",
    "    hours.append(timestamp.hour)\n",
    "    minutes.append(timestamp.minute)\n",
    "\n",
    "X_test = pd.DataFrame()\n",
    "X_test['day'] = days\n",
    "X_test['month'] = months\n",
    "X_test['year'] = years\n",
    "X_test['hour'] = hours\n",
    "X_test['minute'] = minutes\n",
    "X_test.index = df_test.index\n",
    "X_test = X_test.join(df_test[np.concatenate((features, regressands))])\n",
    "\n",
    "X_test = X_test.astype('float32')\n",
    "normalized_X_test=(X_test-X_train.min())/(X_train.max()-X_train.min())\n",
    "#normalized_X_test=(X_test-X_test.min())/(X_test.max()-X_test.min())\n",
    "y_test_min, y_test_max = X_test[regressands].min(), X_test[regressands].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zg9PLrI1Edom",
    "outputId": "1e48c5bf-8b3d-4f70-fca0-0350c06922f2"
   },
   "outputs": [],
   "source": [
    "sizes = np.array([1, 3, 6, 12, 24, 48, 72, 96, 120, 144, 168])*6\n",
    "mae_values = {}\n",
    "#pred_values = {}\n",
    "#real_values = {}\n",
    "rmse_values = {}\n",
    "for i in sizes:\n",
    "    window = i\n",
    "    forseen = i\n",
    "\n",
    "    trainX, trainY = [], []\n",
    "    for j in range(window, len(normalized_X_train.index)-forseen, 1):\n",
    "        input, val = normalized_X_train.values[j-window:j, :], normalized_X_train.values[j:j+forseen,-len(regressands):]  # I know that regressands are the last columns\n",
    "        trainX.append(input)\n",
    "        trainY.append(val)\n",
    "\n",
    "    #val_size = round(len(trainX)*0.25)\n",
    "    val_size = 6*24*60  # 2 months\n",
    "    valX = []\n",
    "    valY = []\n",
    "    for v in range(val_size):\n",
    "        rand_i = random.choice(range(len(trainX)))\n",
    "        valX.append(trainX.pop(rand_i))\n",
    "        valY.append(trainY.pop(rand_i))\n",
    "\n",
    "    trainX = np.array(trainX)\n",
    "    trainY = np.array(trainY)\n",
    "    valX = np.array(valX)\n",
    "    valY = np.array(valY)\n",
    "\n",
    "    testX = []\n",
    "    for t in range(window, len(normalized_X_test.index)-forseen, forseen):\n",
    "        testX.append(normalized_X_test.values[t-window:t, :])\n",
    "    testX = np.array(testX)\n",
    "\n",
    "    # Model\n",
    "    model = Sequential()\n",
    "    model.add(Reshape((window, X_train.shape[1], 1), input_shape=(window, X_train.shape[1])))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(2,1), strides=1, padding='valid', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,1), strides=(1,1)))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(2,1), strides=1, padding='valid', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,1), strides=(1,1)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(64, activation='tanh'))\n",
    "    model.add(Dense(32))\n",
    "    model.add(Dense(forseen*len(regressands)))\n",
    "    model.add(ReLU())\n",
    "    model.add(Reshape((forseen, len(regressands))))\n",
    "\n",
    "    #lr_schedule = ExponentialDecay(initial_learning_rate=0.2, decay_steps=1000, decay_rate=0.9, staircase=False)  # 0.0053 17/30\n",
    "    #opt = Adagrad(learning_rate=lr_schedule)\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', patience=3)\n",
    "    mc = ModelCheckpoint(f'{regressands[0].split(\":\")[0]}/{i//6}H_forecast.h5', monitor='val_loss', mode='min', save_weights_only=True, save_best_only=True)\n",
    "\n",
    "    print(f'Forecasting {i//6}H ahead...')\n",
    "    try:\n",
    "        model.load_weights(f'{regressands[0].split(\":\")[0]}/{i//6}H_forecast.h5')\n",
    "        print('Already trained model found!')\n",
    "    except:\n",
    "        history = model.fit(x=trainX, y=trainY, batch_size=10, epochs=30, shuffle=True, validation_data=(valX, valY), callbacks=[es, mc])\n",
    "    print('\\n------------------------------\\n')\n",
    "\n",
    "    model.load_weights(f'{regressands[0].split(\":\")[0]}/{i//6}H_forecast.h5')\n",
    "\n",
    "    final_pred = model.predict(testX)[:,:,0]*(y_train_max.iloc[0]-y_train_min.iloc[0])+y_train_min.iloc[0]\n",
    "\n",
    "    final_pred = final_pred.reshape((testX.shape[0]*forseen))\n",
    "\n",
    "    mae = (abs(X_test.values[window:window+len(final_pred), -1]-final_pred)).mean()\n",
    "    rmse = math.sqrt(((X_test.values[window:window+len(final_pred), -1]-final_pred)**2).mean())\n",
    "    \n",
    "    mae_values[f'{i//6}H'] = [mae]\n",
    "    rmse_values[f'{i//6}H'] = [rmse]\n",
    "    #pred_values[f'{i//6}H'] = final_pred[:(len(X_test)-window)]\n",
    "    #real_values[f'{i//6}H'] = X_test.values[window:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZYDnAlXznPz"
   },
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "id": "xO4Hzx9TzpL5",
    "outputId": "5a5bc790-23c9-4f5c-b07b-de267475abd4"
   },
   "outputs": [],
   "source": [
    "pred_x = [x//6 for x in sizes]\n",
    "pred_y_rmse = []\n",
    "pred_y_mae = []\n",
    "\n",
    "for k in mae_values.keys():\n",
    "    pred_y_rmse.append(rmse_values[k][0])\n",
    "    pred_y_mae.append(mae_values[k][0])\n",
    "\n",
    "errors_df = pd.DataFrame({'Window [hours]': pred_x, 'MAE': pred_y_mae, 'RMSE': pred_y_rmse})\n",
    "errors_df.to_csv(f'{regressands[0].split(\":\")[0]}/errors.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DoIPKbxfiBtT"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(pred_x, pred_y_mae, label='MAE')\n",
    "plt.plot(pred_x, pred_y_rmse, label='RMSE')\n",
    "plt.xlabel('Forecast window [hours]')\n",
    "plt.title(f'Error on the predicted {regressands[0].split(\":\")[0]} [kWh]')\n",
    "plt.xticks(pred_x)\n",
    "plt.grid()\n",
    "plt.savefig(f'{regressands[0].split(\":\")[0]}/errors_plot')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "BJTx0mMoX2EH",
    "3tTTIC_r5XgX",
    "TkA6sdM1beyw",
    "6Q95_igO1x8I",
    "5tEPVumZb2Uo",
    "Lkjwi-qUERaY"
   ],
   "name": "CNN-LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
